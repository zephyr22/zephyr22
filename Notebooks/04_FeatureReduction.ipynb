{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "# from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import discriminant_analysis\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "- PCA: unsupervised, attempts to retain most variance, direction with the most variance as the first principal componenet, second most the second principal, whiten parameter transforms the values of each prinicpal component so that they have zero meena and unit variance\n",
    "- http://www.math.union.edu/~jaureguj/PCA.pdf\n",
    "- https://www.coursera.org/lecture/machine-learning/choosing-the-number-of-principal-components-S1bq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, (64,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "digits = datasets.load_digits()\n",
    "len(digits), digits['data'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.33501649, -0.04308102,  0.27407152, -0.66447751,\n",
       "       -0.84412939, -0.40972392, -0.12502292, -0.05907756, -0.62400926])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "features = preprocessing.StandardScaler().fit_transform(digits.data)\n",
    "features[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=0.99, whiten=True)\n",
    "features_pca = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (1797, 64)\n",
      "PCA Features: (1797, 54)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"PCA Features: {0}\".format(features_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creeate linearly inseparable data, make_circles: one class is urrounded on all sides by the other\n",
    "nFeatures, _ = datasets.make_circles(n_samples=1000, random_state=1, noise=0.1, factor=0.1)\n",
    "# Apply Kernel PCA with radius basis function kernel (RBF)\n",
    "kpca = decomposition.KernelPCA(kernel='rbf', gamma=15, n_components=1)\n",
    "features_kpca = kpca.fit_transform(nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (1000, 2)\n",
      "PCA Features: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(nFeatures.shape))\n",
    "print(\"PCA Features: {0}\".format(features_kpca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features and Maximize Class Spearability for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Set\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (150, 4)\n",
      "LDA Features: (150, 1)\n",
      "Explained variance kept: [0.9912126]\n"
     ]
    }
   ],
   "source": [
    "# LDA Linear Discriminant Analysis to transform the ffeatures\n",
    "lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=1)\n",
    "features_lda = lda.fit(features, target).transform(features)\n",
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"LDA Features: {0}\".format(features_lda.shape))\n",
    "print(\"Explained variance kept: {0}\".format(lda.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9912126, 0.0087874])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run for all options to determine how many features needed to retain a certain variance by setting n_components to None\n",
    "lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=None)\n",
    "features_lda = lda.fit(features, target)\n",
    "# Get variances\n",
    "lda_var_ratios = lda.explained_variance_ratio_\n",
    "lda_var_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization\n",
    "- feature matrix of non-negative values\n",
    "- Unsupervised linear dimensionality reduction that factorizes, breaks up into multiple matrices whose product approximates the original\n",
    "- V = WH : V is our feature matrix of (features x observations), W is (features x r) and H is an (r x n)  and adjust r to set the amount of dimensionality reduction desired\n",
    "- No explained variance provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "features = digits.data\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (1797, 64)\n",
      "NMF Features: (1797, 10)\n"
     ]
    }
   ],
   "source": [
    "# Create, fit and apply NMF\n",
    "nmf = decomposition.NMF(n_components=10, random_state=1)\n",
    "features_nmf = nmf.fit_transform(features)\n",
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"NMF Features: {0}\".format(features_nmf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Data Feature Reduction\n",
    "- truncated Singular Value Decomposition\n",
    "- provides variance retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "features = preprocessing.StandardScaler().fit_transform(digits.data)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse matrix\n",
    "feature_sparse = sparse.csr_matrix(features)\n",
    "# Create a TSVD\n",
    "tsvd = decomposition.TruncatedSVD(n_components=10)\n",
    "features_tsvd = tsvd.fit(feature_sparse).transform(feature_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (1797, 64)\n",
      "TSVD Features: (1797, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(feature_sparse.shape))\n",
    "print(\"TSVD Features: {0}\".format(features_tsvd.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp 0: 0.12033916097680719\n",
      "Comp 1: 0.21594970477833478\n",
      "Comp 2: 0.30039385369524324\n",
      "Comp 3: 0.3653779284288926\n",
      "Comp 4: 0.4139794572255754\n",
      "Comp 5: 0.4561205799248659\n",
      "Comp 6: 0.4955413762181741\n",
      "Comp 7: 0.5294342908372134\n",
      "Comp 8: 0.5594131619738609\n",
      "Comp 9: 0.5887330248066919\n"
     ]
    }
   ],
   "source": [
    "tot_var = 0\n",
    "for i, ev in enumerate(tsvd.explained_variance_ratio_):\n",
    "    tot_var += ev\n",
    "    print(\"Comp {0}: {1}\".format(i, tot_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "- filter: select best using satistical properties\n",
    "- wrapper: tiral and error to find subset of features that produce models with highest quality predictions\n",
    "- embedded: select best feature as part of algorithms learning/training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only features that have a given variance\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Create Threshold\n",
    "thresh = feature_selection.VarianceThreshold(threshold=0.5)\n",
    "features[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create high variance feature matrix\n",
    "feature_hv = thresh.fit_transform(features)\n",
    "# view high variance feature matrix\n",
    "feature_hv[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- doesn't work when feature sets contain ddifferent units\n",
    "- variance threshold is manual\n",
    "- if features have been standardized then will not work correctly\n",
    "- Categorical: remove those that are predominately 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh.fit(features).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data set: feature 0: 80% c0, feature 1: 80% c1, feature 2: 60 c0\n",
    "my_fea = [[0, 1, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0]]\n",
    "thresholder = feature_selection.VarianceThreshold(threshold=(0.75*0.25))\n",
    "thresholder.fit_transform(my_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highly Correlated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(features)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117570</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.117570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428440</td>\n",
       "      <td>0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.428440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.817941</td>\n",
       "      <td>0.366126</td>\n",
       "      <td>0.962865</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000  0.117570  0.871754  0.817941\n",
       "1  0.117570  1.000000  0.428440  0.366126\n",
       "2  0.871754  0.428440  1.000000  0.962865\n",
       "3  0.817941  0.366126  0.962865  1.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = df.corr().abs()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool))\n",
    "# find columns to ddrop\n",
    "[c for c in upper.columns if any(upper[c] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  5.1  3.5  1.4\n",
       "1  4.9  3.0  1.4\n",
       "2  4.7  3.2  1.3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([c for c in upper.columns if any(upper[c] > 0.95)], axis=1).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Irrelevant Features for Classification\n",
    "- Calculate a chi-square statistic between each feature and the target: difference between the observed number of observations in each class and what we woul expect if the feature was independent\n",
    "- quantitative features, compute the ANOVA F-value betwewen each featuer and target vector: are the means statistically different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to categorical\n",
    "features = features.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select two with highest chi-square statistic\n",
    "chi2_selector = feature_selection.SelectKBest(feature_selection.chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (150, 4)\n",
      "Chi Features: (150, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"Chi Features: {0}\".format(features_kbest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 2 features with highest f-value\n",
    "fvalue_selector = feature_selection.SelectKBest(feature_selection.f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (150, 4)\n",
      "Chi Features: (150, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"Chi Features: {0}\".format(features_kbest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select percentile of features with highest f-value\n",
    "fvalue_selector = feature_selection.SelectPercentile(feature_selection.f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: (150, 4)\n",
      "Chi Features: (150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Features: {0}\".format(features.shape))\n",
    "print(\"Chi Features: {0}\".format(features_kbest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination w/ Cross Validation\n",
    "repeatedly train a model removing a featuer until model performance becomes worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "features, target = datasets.make_regression(n_samples=1000, n_features=100, n_informative=3, random_state=1)\n",
    "# model\n",
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenn\\Anaconda3\\envs\\everyday\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.71242059, -1.42855575,  0.20271102],\n",
       "       [ 0.63015866, -0.6579047 , -0.78209345],\n",
       "       [-1.33953296,  0.86635759, -2.02573104],\n",
       "       ...,\n",
       "       [ 2.26534949,  0.15301017,  1.32665135],\n",
       "       [-0.48969413,  1.95787748, -0.00832094],\n",
       "       [-1.06119079,  0.11066107, -1.07171859]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recurrsion\n",
    "rfecv = feature_selection.RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of best features: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of best features: {0}\".format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76, 13, 61, 20, 83, 74, 58, 52, 62, 97, 80, 81, 59, 30, 72, 60, 98,\n",
       "       35,  9, 27,  7, 92, 78, 34, 19, 70, 18, 43, 77, 53, 84, 47,  1, 89,\n",
       "       38, 95, 10, 55, 63,  4, 16, 69,  6,  5,  3, 67, 85, 42, 65, 93, 82,\n",
       "       26, 94, 31, 54, 75, 36, 64, 96, 17, 22, 33, 91, 39, 37, 46, 66, 40,\n",
       "       45, 86, 51,  1, 25, 79, 57,  8, 88, 87, 24,  2, 90, 15, 50, 28, 14,\n",
       "        1, 49, 71, 11, 44, 29, 68, 32, 41, 21, 56, 73, 23, 12, 48])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
