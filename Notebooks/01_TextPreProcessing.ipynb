{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from nltk import corpus\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import porter\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text\n",
    "- Stip whitespace\n",
    "- remove punctuation\n",
    "- same case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_one = [\"  I like chocolate. \", \" Please, no more! \", \"Check the fridge. . . . \"]\n",
    "html_text = \"\"\"\n",
    "    <div class='sample'> <span style='font-weight:bold'> This is it </span> BLAH!! </div> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i like chocolate.', 'please, no more!', 'check the fridge. . . .']\n"
     ]
    }
   ],
   "source": [
    "# Stip Whitespace & lowercase\n",
    "cleaned_one = [sent.lower().strip() for sent in text_one]\n",
    "print(cleaned_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i like chocolate', 'please no more', 'check the fridge']\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation: could use: string.replace()\n",
    "def remove_punc(my_text):\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", my_text)\n",
    "cleaned_one = [remove_punc(sent).strip() for sent in cleaned_one]\n",
    "print(cleaned_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parses HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  This is it  BLAH!! '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_text)\n",
    "soup.find(\"div\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of punctuation characters with None as values\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  I like chocolate ', ' Please no more ', 'Check the fridge    ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "[string.translate(punctuation) for string in text_one]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'chocolate', 'please', 'no', 'more', 'check', 'the', 'fridge']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_strings = [tokenize.word_tokenize(x) for x in cleaned_one]\n",
    "my_strings = my_strings[0] + my_strings[1] + my_strings[2]\n",
    "my_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jenn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['like', 'chocolate', 'please', 'check', 'fridge']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to download stop words first time\n",
    "nltk.download('stopwords')\n",
    "# load stopwords\n",
    "stop_words = corpus.stopwords.words('english')\n",
    "# Remove\n",
    "[word for word in my_strings if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'chocol', 'pleas', 'no', 'more', 'check', 'the', 'fridg']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Stemmer\n",
    "my_porter = porter.PorterStemmer()\n",
    "# Apply Stemmer\n",
    "[my_porter.stem(word) for word in my_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Parts of Speech\n",
    "NLTK uses the Penn Treebank parts for speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like chocolate please no more check the fridge'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence = \" \".join(my_strings)\n",
    "my_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NNS'),\n",
       " ('like', 'VBP'),\n",
       " ('chocolate', 'NN'),\n",
       " ('please', 'NN'),\n",
       " ('no', 'DT'),\n",
       " ('more', 'JJR'),\n",
       " ('check', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('fridge', 'NN')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tagged = pos_tag(word_tokenize(my_sentence))\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'chocolate', 'please', 'fridge']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Nouns:\n",
    "[word for word, tag in text_tagged if tag in ('NN', 'NNS', 'NNP', 'NNPS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of getting the parts of speech of tweets and one_hot encoding what is present\n",
    "tweets = [\"Chocolate cake is here to stay\", \"The buck stops here pal\", \"This is where I am going\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NNP', 'NN', 'VBZ', 'RB', 'TO', 'VB'],\n",
       " ['DT', 'NN', 'VBZ', 'RB', 'JJ'],\n",
       " ['DT', 'VBZ', 'WRB', 'PRP', 'VBP', 'VBG']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tweets = []\n",
    "for tweet in tweets:\n",
    "    tweet_tag = pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])\n",
    "tagged_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot encoding\n",
    "tweet_one_hot = preprocessing.MultiLabelBinarizer()\n",
    "tweet_one_hot.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNP</th>\n",
       "      <th>PRP</th>\n",
       "      <th>RB</th>\n",
       "      <th>TO</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT  JJ  NN  NNP  PRP  RB  TO  VB  VBG  VBP  VBZ  WRB\n",
       "0   0   0   1    1    0   1   1   1    0    0    1    0\n",
       "1   1   1   1    0    0   1   0   0    0    0    1    0\n",
       "2   1   0   0    0    1   0   0   0    1    1    1    1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tweet_one_hot.fit_transform(tagged_tweets), columns=tweet_one_hot.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating own Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Robert', 'NP'),\n",
       " ('Snodgrass', 'NP'),\n",
       " (',', ','),\n",
       " ('state', 'NN'),\n",
       " ('GOP', 'NN'),\n",
       " ('chairman', 'NN'),\n",
       " (',', ','),\n",
       " ('said', 'VBD'),\n",
       " ('a', 'AT'),\n",
       " ('meeting', 'NN'),\n",
       " ('held', 'VBN'),\n",
       " ('Tuesday', 'NR'),\n",
       " ('night', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Blue', 'JJ-TL'),\n",
       " ('Ridge', 'NN-TL'),\n",
       " ('brought', 'VBD'),\n",
       " ('enthusiastic', 'JJ'),\n",
       " ('responses', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('audience', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sentences\n",
    "sentences = corpus.brown.tagged_sents(categories='news')\n",
    "sentences[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sentences[:4000]\n",
    "test = sentences[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backoff taggerer\n",
    "unigram = tag.UnigramTagger(train)\n",
    "bigram = tag.BigramTagger(train, backoff=unigram)\n",
    "trigram = tag.TrigramTagger(train, backoff=bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174734002697437"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chocolate cake is here to stay', 'The buck stops here pal',\n",
       "       'This is where I am going'], dtype='<U30')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = np.array(tweets)\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_counts = CountVectorizer()\n",
    "word_bag = my_counts.fit_transform(text_data)\n",
    "word_bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>buck</th>\n",
       "      <th>cake</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>going</th>\n",
       "      <th>here</th>\n",
       "      <th>is</th>\n",
       "      <th>pal</th>\n",
       "      <th>stay</th>\n",
       "      <th>stops</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>to</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  buck  cake  chocolate  going  here  is  pal  stay  stops  the  this  \\\n",
       "0   0     0     1          1      0     1   1    0     1      0    0     0   \n",
       "1   0     1     0          0      0     1   0    1     0      1    1     0   \n",
       "2   1     0     0          0      1     0   1    0     0      0    0     1   \n",
       "\n",
       "   to  where  \n",
       "0   1      0  \n",
       "1   0      0  \n",
       "2   0      1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the features\n",
    "pd.DataFrame(word_bag.toarray(), columns=my_counts.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer:\n",
    "- Stores as a sparse matrix by default\n",
    "- ngram_range parameter to determine if single words or two words or more\n",
    "- stop_words parameter to remove unimportant\n",
    "- vocabulary parameter to restrict to only certain words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting Word Importance\n",
    "term  frequency-inverse document frequency (tf-idf)\n",
    "- Term Frequency: more a word appears in a document the more likely it is important\n",
    "- Document Frequency: if a word appears in every document it is probably not that important\n",
    "- mulitple tf by the inverse of document frequency\n",
    "- sklearn normalizes the tf-idf vectors using L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chocolate cake is here to stay', 'The buck stops here pal',\n",
       "       'This is where I am going'], dtype='<U30')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.44036207, 0.44036207, 0.        ,\n",
       "        0.3349067 , 0.3349067 , 0.        , 0.44036207, 0.        ,\n",
       "        0.        , 0.        , 0.44036207, 0.        ],\n",
       "       [0.        , 0.46735098, 0.        , 0.        , 0.        ,\n",
       "        0.35543247, 0.        , 0.46735098, 0.        , 0.46735098,\n",
       "        0.46735098, 0.        , 0.        , 0.        ],\n",
       "       [0.46735098, 0.        , 0.        , 0.        , 0.46735098,\n",
       "        0.        , 0.35543247, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46735098, 0.        , 0.46735098]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>cake</th>\n",
       "      <th>is</th>\n",
       "      <th>here</th>\n",
       "      <th>to</th>\n",
       "      <th>stay</th>\n",
       "      <th>the</th>\n",
       "      <th>buck</th>\n",
       "      <th>stops</th>\n",
       "      <th>pal</th>\n",
       "      <th>this</th>\n",
       "      <th>where</th>\n",
       "      <th>am</th>\n",
       "      <th>going</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334907</td>\n",
       "      <td>0.334907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate      cake        is      here        to      stay       the  \\\n",
       "0   0.000000  0.000000  0.440362  0.440362  0.000000  0.334907  0.334907   \n",
       "1   0.000000  0.467351  0.000000  0.000000  0.000000  0.355432  0.000000   \n",
       "2   0.467351  0.000000  0.000000  0.000000  0.467351  0.000000  0.355432   \n",
       "\n",
       "       buck     stops       pal      this     where        am     going  \n",
       "0  0.000000  0.440362  0.000000  0.000000  0.000000  0.440362  0.000000  \n",
       "1  0.467351  0.000000  0.467351  0.467351  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.467351  0.000000  0.467351  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_matrix.toarray(), columns=tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
